{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82bcbc8d-a536-4131-8c83-2f8b59fc27f6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "# from logger import LoggerSetup\n",
    "from typing import Any\n",
    "\n",
    "class DataHandler:\n",
    "    def __init__(self):\n",
    "        # self.log = LoggerSetup(logger_file = 'data_handler.log',\n",
    "        #                        logger_name = 'data_handler').get_logger()\n",
    "        pass\n",
    "\n",
    "    def load_data(self, input_data : str = None):\n",
    "        try:\n",
    "            _, extension = os.path.splitext(input_data)\n",
    "            if extension == '.csv':\n",
    "                data = pd.read_csv(input_data)\n",
    "                return data\n",
    "            \n",
    "            elif extension == ['.xlx', '.xlsx']:\n",
    "                data = pd.read_excel(input_data)\n",
    "                return data\n",
    "            \n",
    "            else:\n",
    "                print(\"File not found. Please load file with extension: 'csv', 'xls', 'xlsx'.\")\n",
    "\n",
    "        except FileNotFoundError as e:\n",
    "            print(f\"Unable to find the document you're trying to load. {e}\")\n",
    "\n",
    "    def save_data(self, result : Any = None, output_file : str = None):\n",
    "        try:\n",
    "            print('Saving file...')\n",
    "            result.to_csv(output_file, encoding = 'utf-8', index = False)\n",
    "            print(f'Saved results to {output_file}.')\n",
    "\n",
    "        except Exception as e:\n",
    "            self.log.error(f'Unable to save CSV. {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b678ab3-9466-4199-b8d0-e3b3d9604c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats.mstats import winsorize\n",
    "# from src import DataHandler\n",
    "# from logger import LoggerSetup\n",
    "\n",
    "class Preprocessor:\n",
    "    def __init__(self, input_data : str = None):\n",
    "        self.handler    = DataHandler()\n",
    "        self.input_data = self.handler.load_data(input_data)\n",
    "        # self.log        = LoggerSetup(logger_file = 'preprocessor.log',\n",
    "        #                               logger_name = 'preprocessor').get_logger()\n",
    "        \n",
    "    def view_data(self):\n",
    "        return self.input_data.head(10)\n",
    "\n",
    "    def data_size(self):\n",
    "        return self.input_data.shape\n",
    "\n",
    "    def check_null(self):\n",
    "        return self.input_data.isnull().sum()\n",
    "\n",
    "    def check_unique_values(self):\n",
    "        return self.input_data.nunique()\n",
    "\n",
    "    def drop_columns(self, column):\n",
    "        data = self.input_data.drop(column, axis = 1)\n",
    "        self.input_data = data\n",
    "        return self.input_data\n",
    "\n",
    "    def check_duplicates(self):\n",
    "        return self.input_data.duplicated().value_counts()\n",
    "\n",
    "    def remove_duplicate_rows(self):\n",
    "        return self.input_data.drop_duplicates()\n",
    "\n",
    "    def check_column_types(self):\n",
    "        return self.input_data.dtypes\n",
    "\n",
    "    def correct_spelling(self, original, column, replace):\n",
    "        self.input_data[column] = self.input_data[column].replace({original : replace})\n",
    "        return self.input_data\n",
    "\n",
    "    def checking_outliers(self, column_name : str = None):\n",
    "        # Column name from quantity, price and sale\n",
    "        sns.boxplot(self.input_data[column_name])\n",
    "        plt.title(f\"Outliers in {column_name}\")\n",
    "        plt.show()\n",
    "\n",
    "    # def winsorize_outliers(self, column_name : str = None):\n",
    "    #     winsorized_data = {}\n",
    "    #     winsorized_data[column_name] = winsorize(self.input_data[column_name], limits = [0.00, 0.05])\n",
    "    #     print(f\"Mean of original data {column_name}:\", np.mean(self.input_data[column_name]))\n",
    "    #     print(f\"Mean of winsorized data {column_name}:\", np.mean(winsorized_data[column_name]))\n",
    "    #     self.input_data[column_name] = winsorized_data[column_name]\n",
    "\n",
    "    #     return self.input_data\n",
    "\n",
    "    def transform_values(self, column_name : str = None):\n",
    "        self.input_data[column_name] = abs(self.input_data[column_name])\n",
    "        return self.input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e1d82eb2-3241-4592-9f6f-e87b7b3589e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Distributor             29\n",
       "Customer Name          751\n",
       "City                   749\n",
       "Country                  2\n",
       "Latitude               655\n",
       "Longitude              709\n",
       "Channel                  2\n",
       "Sub-channel              4\n",
       "Product Name           240\n",
       "Product Class            6\n",
       "Quantity              1735\n",
       "Price                  210\n",
       "Sales                20546\n",
       "Month                   12\n",
       "Year                     4\n",
       "Name of Sales Rep       13\n",
       "Manager                  4\n",
       "Sales Team               4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor = Preprocessor(input_data = '../data/pharma-data.csv')\n",
    "preprocessor.check_unique_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab23515b-5e8a-41b1-b448-de39397ee5bc",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.exceptions as pe\n",
    "import plotly.graph_objects as go\n",
    "from scipy.stats import chisquare\n",
    "from typing import List, Dict, Any\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "\n",
    "class DataAnalysis:\n",
    "    def __init__(self, input_data : str = None):\n",
    "        self.handler = DataHandler()\n",
    "        self.input_data = self.handler.load_data(input_data)\n",
    "\n",
    "    def data_description(self):\n",
    "        return self.input_data.describe()\n",
    "\n",
    "    def calculate_kpi(self):\n",
    "        total_sale     = sum(self.input_data['Sale'])\n",
    "        total_cost     = sum(self.input_data['Price'])\n",
    "        total_quantity = sum(self.input_data['Quantity'])\n",
    "        total_profit   = total_sale - total_cost\n",
    "        \n",
    "        average_sale   = total_sale/self.input_data.value_counts()\n",
    "        average_cost   = total_cost/self.input_data.value_counts()\n",
    "\n",
    "        profit_margin  = total_profit/total_cost*100\n",
    "\n",
    "        return (total_sale, total_cost, total_quantity, \n",
    "                total_profit, average_sale, average_cost, \n",
    "                profit_margin)\n",
    "\n",
    "    def express_skewness(self, column_name : str = None):\n",
    "        skewness = skew(self.input_data[column_name])\n",
    "        return skewness\n",
    "\n",
    "    def express_kurtosis(self, column_name : str = None):\n",
    "        kurtosis_val = kurtosis(self.input_data[column_name])\n",
    "        return kurtosis_val\n",
    "\n",
    "    def check_distribution(self, column = None):\n",
    "        observation = self.input_data[column].value_counts().sort_index()\n",
    "        total_observations = sum(observation)\n",
    "        expected = [total_observations/len(observation)]*len(observation)\n",
    "\n",
    "        chi2stat , p_value = chisquare(observation, expected)\n",
    "\n",
    "        print(f'Chi-Square Statistic: {chi2stat}\\n P-Value: {p_value}')\n",
    "\n",
    "    def correlation_test(self):\n",
    "        data = self.input_data.select_dtypes(include=['number'])\n",
    "        correlation_matrix = data.corr(method='pearson')\n",
    "\n",
    "        # Create interactive heatmap\n",
    "        fig = px.imshow(correlation_matrix,\n",
    "                        text_auto=True,\n",
    "                        color_continuous_scale='RdYlGn',\n",
    "                        title='Pearson Correlation Matrix')\n",
    "        return fig\n",
    "\n",
    "    def covariance_calculation(self, column1, column2):\n",
    "        covariance_matrix = np.cov(self.input_data[column1], self.input_data[column2])\n",
    "        return covariance_matrix\n",
    "\n",
    "da = DataAnalysis(input_data = '../data/preprocessed_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0179cc43-0b57-4753-93de-da3d191e88c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.exceptions as pe\n",
    "import plotly.graph_objects as go\n",
    "from scipy.stats import chisquare\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "class ExploratoryDataAnalysis:\n",
    "    def __init__(self, input_data):\n",
    "        self.handler = DataHandler()\n",
    "        self.input_data = self.handler.load_data(input_data = input_data)\n",
    "        \n",
    "    # DISTRIBUTION PLOTS\n",
    "    def distribution(self, column_name):\n",
    "        fig = px.histogram(self.input_data,\n",
    "                           x        = column_name,\n",
    "                           title    = f'Distribution of {column_name} using Histogram',\n",
    "                           nbins    = 20,)\n",
    "        return fig\n",
    "\n",
    "    def violin_plot(self, column_name):\n",
    "        fig = px.violin(self.input_data,\n",
    "                        x        = column_name,\n",
    "                        title    = f'Distribution of {column_name} using Histogram',)\n",
    "        return fig\n",
    "\n",
    "    def bar_plot_categories(self, column_name):\n",
    "        fig = px.bar(self.input_data,\n",
    "                     x     = column_name,\n",
    "                     title = f'Count of {column_name} using Bar Graph',\n",
    "                     color = column_name)\n",
    "        return fig\n",
    "\n",
    "    def pie_chart(self, column_name):\n",
    "        column_sale = self.input_data.groupby(column_name, as_index = False)['Sales'].sum()\n",
    "        fig = px.pie(column_sale,\n",
    "                     values = 'Sales',\n",
    "                     names  = column_name,\n",
    "                     title  = f'Sale percentage based on {column_name}',\n",
    "                     color = column_name,)\n",
    "        return fig\n",
    "\n",
    "eda = ExploratoryDataAnalysis(input_data = '../data/preprocessed_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d136bad-f936-42b2-8350-98d6ade76d54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
